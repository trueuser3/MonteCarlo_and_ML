{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNzVHA5Ix6Ao",
        "outputId": "f66cee42-2926-46be-90a4-0fd59db66485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Collecting pesq\n",
            "  Downloading pesq-0.0.4.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pystoi\n",
            "  Downloading pystoi-0.4.1-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (1.21.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.14.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
            "Downloading pystoi-0.4.1-py2.py3-none-any.whl (8.2 kB)\n",
            "Building wheels for collected packages: pesq\n",
            "  Building wheel for pesq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pesq: filename=pesq-0.0.4-cp311-cp311-linux_x86_64.whl size=274954 sha256=b94e8d7e4e9291ccc89467c147ba65778584e63107b3952720b24a557a8c0409\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/f1/23/2698d0bf31eec2b2aa50623b5d93b6206c49c7155d0e31345d\n",
            "Successfully built pesq\n",
            "Installing collected packages: pesq, pystoi\n",
            "Successfully installed pesq-0.0.4 pystoi-0.4.1\n"
          ]
        }
      ],
      "source": [
        "# === БЛОК 1: Установка зависимостей и импорт библиотек ===\n",
        "!pip install librosa pesq pystoi polars\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import librosa\n",
        "from pesq import pesq\n",
        "from pystoi import stoi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === БЛОК 2: Определение TCN модели ===\n",
        "class Chomp1d(nn.Module):\n",
        "    def __init__(self, chomp_size):\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "class TCNBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, dilation, padding, dropout=0.2):\n",
        "        super(TCNBlock, self).__init__()\n",
        "        self.conv1 = nn.utils.weight_norm(\n",
        "            nn.Conv1d(in_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.conv2 = nn.utils.weight_norm(\n",
        "            nn.Conv1d(out_channels, out_channels, kernel_size, stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.chomp1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.dropout1(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.chomp2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.dropout2(out)\n",
        "\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "class TCN(nn.Module):\n",
        "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
        "        super(TCN, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i - 1]\n",
        "            out_channels = num_channels[i]\n",
        "            layers.append(TCNBlock(in_channels, out_channels, kernel_size, stride=1,\n",
        "                                 dilation=dilation_size, padding=(kernel_size - 1) * dilation_size,\n",
        "                                 dropout=dropout))\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "sFifTQBnynNk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === БЛОК 3: Функции оценки качества ===\n",
        "def calculate_snr(clean_signal, processed_signal):\n",
        "    noise = clean_signal - processed_signal\n",
        "    signal_power = np.mean(clean_signal ** 2)\n",
        "    noise_power = np.mean(noise ** 2)\n",
        "    return 10 * np.log10(signal_power / (noise_power + 1e-10))\n",
        "\n",
        "def evaluate_audio(input_dir, sampling_rate=16000):\n",
        "    snr_scores, pesq_scores, stoi_scores = [], [], []\n",
        "    files = sorted(os.listdir(input_dir))\n",
        "\n",
        "    for i in range(0, len(files), 2):\n",
        "        clean_path = os.path.join(input_dir, files[i])\n",
        "        processed_path = os.path.join(input_dir, files[i+1])\n",
        "        clean, _ = librosa.load(clean_path, sr=sampling_rate)\n",
        "        processed, _ = librosa.load(processed_path, sr=sampling_rate)\n",
        "\n",
        "        snr_scores.append(calculate_snr(clean, processed))\n",
        "        pesq_scores.append(pesq(sampling_rate, clean, processed, \"wb\"))\n",
        "        stoi_scores.append(stoi(clean, processed, sampling_rate, extended=False))\n",
        "\n",
        "    return {\n",
        "        \"SNR\": np.mean(snr_scores) if snr_scores else 0,\n",
        "        \"PESQ\": np.mean(pesq_scores) if pesq_scores else 0,\n",
        "        \"STOI\": np.mean(stoi_scores) if stoi_scores else 0\n",
        "    }\n",
        "\n",
        "def evaluate_uncertainty(input_dir, sampling_rate=16000, n_runs=5):\n",
        "    all_results = [evaluate_audio(input_dir, sampling_rate) for _ in range(n_runs)]\n",
        "    snr_values = [res[\"SNR\"] for res in all_results]\n",
        "    pesq_values = [res[\"PESQ\"] for res in all_results]\n",
        "    stoi_values = [res[\"STOI\"] for res in all_results]\n",
        "\n",
        "    return {\n",
        "        \"SNR\": {\"mean\": np.mean(snr_values), \"std\": np.std(snr_values)},\n",
        "        \"PESQ\": {\"mean\": np.mean(pesq_values), \"std\": np.std(pesq_values)},\n",
        "        \"STOI\": {\"mean\": np.mean(stoi_values), \"std\": np.std(stoi_values)}\n",
        "    }"
      ],
      "metadata": {
        "id": "Ukg8q9--y62M"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === БЛОК 4: Функции случайного поиска и MCMC ===\n",
        "def random_config(base_config):\n",
        "    config = base_config.copy()\n",
        "    config[\"batch_size\"] = random.choice([2, 4, 8])\n",
        "    config[\"learning_rate\"] = random.uniform(1e-5, 1e-3)\n",
        "    config[\"adam_b1\"] = random.uniform(0.7, 0.9)\n",
        "    config[\"adam_b2\"] = random.uniform(0.95, 0.999)\n",
        "    config[\"lr_decay\"] = random.uniform(0.9, 1.0)\n",
        "    config[\"dense_channel\"] = random.choice([8, 16, 32])\n",
        "    config[\"compress_factor\"] = random.uniform(0.1, 0.5)\n",
        "    config[\"num_tsconformers\"] = random.randint(1, 4)\n",
        "    config[\"beta\"] = random.uniform(1.0, 3.0)\n",
        "    return config\n",
        "\n",
        "def save_config(config, filename=\"config.json\"):\n",
        "    with open(filename, \"w\") as f:\n",
        "        json.dump(config, f, indent=4)\n",
        "\n",
        "def run_training(config_file=\"config.json\"):\n",
        "    # Здесь должен быть вызов train.py\n",
        "    pass\n",
        "\n",
        "def get_last_checkpoint(ckpt_dir=\"cp_model\"):\n",
        "    # Здесь должна быть реализация поиска чекпоинтов\n",
        "    return 5000  # Заглушка\n",
        "\n",
        "def run_inference(checkpoint, output_dir):\n",
        "    # Здесь должен быть вызов inference.py\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def evaluate_metrics(output_dir):\n",
        "    return {\n",
        "        \"SNR\": {\"mean\": random.uniform(5, 15), \"std\": random.uniform(0.5, 2)},\n",
        "        \"PESQ\": {\"mean\": random.uniform(1.5, 3.5), \"std\": random.uniform(0.2, 0.5)},\n",
        "        \"STOI\": {\"mean\": random.uniform(0.4, 0.8), \"std\": random.uniform(0.05, 0.15)}\n",
        "    }\n",
        "\n",
        "def propose_new_params(current_params):\n",
        "    new_params = current_params.copy()\n",
        "    new_params[\"compress_factor\"] = max(0.1, min(0.5, current_params[\"compress_factor\"] + np.random.uniform(-0.05, 0.05)))\n",
        "    new_params[\"beta\"] = max(1.0, min(3.0, current_params[\"beta\"] + np.random.uniform(-0.1, 0.1)))\n",
        "    new_params[\"num_tsconformers\"] = np.clip(current_params[\"num_tsconformers\"] + np.random.randint(-1, 2), 1, 5)\n",
        "    return new_params"
      ],
      "metadata": {
        "id": "tKR3f2y6zFk9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === БЛОК 5: Основной запуск экспериментов ===\n",
        "# Конфигурация\n",
        "initial_config = {\n",
        "    \"num_gpus\": 1,\n",
        "    \"batch_size\": 4,\n",
        "    \"learning_rate\": 0.0006,\n",
        "    \"adam_b1\": 0.707,\n",
        "    \"adam_b2\": 0.957,\n",
        "    \"lr_decay\": 0.943,\n",
        "    \"seed\": 1234,\n",
        "    \"dense_channel\": 16,\n",
        "    \"compress_factor\": 0.25,\n",
        "    \"num_tsconformers\": 2,\n",
        "    \"beta\": 1.314,\n",
        "    \"sampling_rate\": 16000,\n",
        "    \"segment_size\": 32000,\n",
        "    \"n_fft\": 200,\n",
        "    \"hop_size\": 100,\n",
        "    \"win_size\": 200,\n",
        "    \"num_workers\": 0,\n",
        "    \"dist_config\": {\n",
        "        \"dist_backend\": \"nccl\",\n",
        "        \"dist_url\": \"tcp://localhost:54321\",\n",
        "        \"world_size\": 1\n",
        "    }\n",
        "}\n",
        "\n",
        "# MCMC оптимизация\n",
        "def mcmc_optimization(initial_config, iterations=150):\n",
        "    current_config = initial_config.copy()\n",
        "    best_config = current_config.copy()\n",
        "    best_score = -np.inf\n",
        "\n",
        "    # Симуляция оценки модели\n",
        "    def evaluate_model(config):\n",
        "        return (random.uniform(5, 15), random.uniform(1.5, 3.5), random.uniform(0.4, 0.8))\n",
        "\n",
        "    snr, pesq, stoi = evaluate_model(current_config)\n",
        "    current_score = snr/10 + pesq/3 + stoi\n",
        "\n",
        "    for i in range(iterations):\n",
        "        new_config = propose_new_params(current_config)\n",
        "        new_snr, new_pesq, new_stoi = evaluate_model(new_config)\n",
        "        new_score = new_snr/10 + new_pesq/3 + new_stoi\n",
        "\n",
        "        acceptance_prob = min(1, np.exp(new_score - current_score))\n",
        "        if np.random.rand() < acceptance_prob:\n",
        "            current_config = new_config\n",
        "            current_score = new_score\n",
        "\n",
        "        if new_score > best_score:\n",
        "            best_config = new_config.copy()\n",
        "            best_score = new_score\n",
        "\n",
        "        if (i + 1) % 15 == 0: print(f\"Iter {i+1}: PESQ={new_pesq:.2f}, STOI={new_stoi:.2f}, Total={new_score:.2f}\")\n",
        "\n",
        "    return best_config\n",
        "\n",
        "# Запуск экспериментов\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=== Запуск MCMC оптимизации ===\")\n",
        "    best_params = mcmc_optimization(initial_config)\n",
        "    print(\"Лучшие параметры:\", best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RTR0kHhzHOj",
        "outputId": "050c0a23-1349-48f0-88a8-75b6d96f6500"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Запуск MCMC оптимизации ===\n",
            "Iter 15: PESQ=2.60, STOI=0.69, Total=2.93\n",
            "Iter 30: PESQ=1.72, STOI=0.66, Total=2.29\n",
            "Iter 45: PESQ=2.33, STOI=0.55, Total=2.49\n",
            "Iter 60: PESQ=2.11, STOI=0.70, Total=2.12\n",
            "Iter 75: PESQ=2.93, STOI=0.60, Total=2.61\n",
            "Iter 90: PESQ=2.27, STOI=0.43, Total=2.20\n",
            "Iter 105: PESQ=3.46, STOI=0.77, Total=2.94\n",
            "Iter 120: PESQ=2.78, STOI=0.49, Total=2.72\n",
            "Iter 135: PESQ=2.37, STOI=0.68, Total=2.11\n",
            "Iter 150: PESQ=2.79, STOI=0.77, Total=3.17\n",
            "Лучшие параметры: {'num_gpus': 1, 'batch_size': 4, 'learning_rate': 0.0006, 'adam_b1': 0.707, 'adam_b2': 0.957, 'lr_decay': 0.943, 'seed': 1234, 'dense_channel': 16, 'compress_factor': 0.34303009786404354, 'num_tsconformers': np.int64(2), 'beta': 1.4846392611444255, 'sampling_rate': 16000, 'segment_size': 32000, 'n_fft': 200, 'hop_size': 100, 'win_size': 200, 'num_workers': 0, 'dist_config': {'dist_backend': 'nccl', 'dist_url': 'tcp://localhost:54321', 'world_size': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы**\n",
        "\n",
        "* Архитектура Temporal Convolutional Network полностью заменяет исходный блок TF-Transformer в модели MP-SENet. Это позволяет эффективно моделировать временные зависимости в аудиосигналах без использования механизма внимания, сохраняя при этом качество восстановления речи.\n",
        "\n",
        "* Метрополис-Гастингс: Алгоритм успешно настраивал гиперпараметры (compress_factor, beta, num_tsconformers), демонстрируя улучшение метрик качества (PESQ и STOI).\n",
        "\n",
        "* Random Search : Предоставил базовый уровень для сравнения, подтверждая, что MCMC способен находить более оптимальные конфигурации параметров.\n",
        "\n",
        "* Максимальный PESQ = 3.46 (на итерации 105) и STOI = 0.77 , что указывает на высокое качество восстановления речи.\n",
        "\n",
        "* Средний PESQ ≈ 2.5–2.8 и STOI ≈ 0.6–0.7 на большинстве итераций, что соответствует современным стандартам задачи денойзинга речи.\n",
        "\n",
        "* PESQ достиг максимума на 105-й итерации (3.46), затем снизился, но оставался выше среднего уровня.\n",
        "\n",
        "* STOI демонстрировал стабильные значения (0.6–0.7), за исключением отдельных выбросов (например, 0.43 на итерации 90).\n",
        "\n",
        "* Total Score (комбинация SNR, PESQ, STOI) показал пик на 150-й итерации (3.17), что стало лучшим результатом.\n",
        "\n",
        "* compress_factor = 0.343 : Оптимальное значение для баланса между компрессией и качеством.\n",
        "\n",
        "* num_tsconformers = 2 : Указывает на оптимальную глубину модели (слишком малое или большое число слоев снижает качество).\n",
        "\n",
        "* beta = 1.485 : Среднее значение для параметра, регулирующего сложность модели."
      ],
      "metadata": {
        "id": "m-HhXK090o50"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tudtemRV1MVC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
