{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import random\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "\n",
        "class TextClassifier:\n",
        "    def __init__(self, model_name=\"Qwen/Qwen3-0.6B\"):\n",
        "        # Уменьшаем потребление памяти\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "            device_map=\"auto\",\n",
        "            low_cpu_mem_usage=True\n",
        "        )\n",
        "        # Освобождаем память\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        self.classes = [\"sport\", \"technology\", \"culinary\", \"politics\", \"health\"]\n",
        "        self.temperatures = [0.5, 0.7, 1.0, 1.2, 1.5]\n",
        "        self.examples = self._create_examples()\n",
        "\n",
        "    def _create_examples(self):\n",
        "        return [\n",
        "            {\"text\": \"Баскетболисты ЦСКА одержали уверенную победу над испанским «Реалом» в Евролиге.\", \"label\": \"sport\"},\n",
        "            {\"text\": \"Квантовые компьютеры MIT научились решать задачи за секунды, которые обычным системам требовались дни.\", \"label\": \"technology\"},\n",
        "            {\"text\": \"Как приготовить домашнюю лапшу рамен за 30 минут — пошаговый гид с фотографиями.\", \"label\": \"culinary\"},\n",
        "            {\"text\": \"Выборы в Европарламент 2024: рост популярности экологических партий в Германии и Франции.\", \"label\": \"politics\"},\n",
        "            {\"text\": \"Психологические практики: эффективные методы борьбы с тревожностью без лекарств.\", \"label\": \"health\"}\n",
        "        ]\n",
        "\n",
        "    def _build_prompt(self, text, examples=None):\n",
        "        system_msg = \"Вы классифицируете текст по категориям: sport, technology, culinary, politics, health. Ответьте только названием категории.\"\n",
        "        user_msg = f\"Текст: {text}\\nКатегория:\"\n",
        "\n",
        "        if examples:\n",
        "            user_msg = \"\"\n",
        "            for ex in examples:\n",
        "                user_msg += f\"\\nТекст: {ex['text']}\\nКатегория: {ex['label']}\\n\"\n",
        "            user_msg += f\"\\nТекст: {text}\\nКатегория:\"\n",
        "\n",
        "        return [\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_msg.strip()}\n",
        "        ]\n",
        "\n",
        "    def _generate(self, text, examples=None, temperature=0.7, max_tokens=100):\n",
        "        try:\n",
        "            messages = self._build_prompt(text, examples)\n",
        "            prompt = self.tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                tokenize=False,\n",
        "                add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096).to(self.model.device)\n",
        "\n",
        "            # Уменьшаем максимальное количество токенов\n",
        "            outputs = self.model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_tokens,\n",
        "                temperature=temperature,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "            output_ids = outputs[0][inputs.input_ids.shape[1]:]\n",
        "            return self.tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка генерации: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def _parse_output(self, output):\n",
        "        # Простая проверка без JSON\n",
        "        output = output.lower().replace('\"', '').replace(\"'\", \"\").strip()\n",
        "        for cls in self.classes:\n",
        "            if cls in output:\n",
        "                return {c: 1 if c == cls else 0 for c in self.classes}\n",
        "        return {cls: 0 for cls in self.classes}\n",
        "\n",
        "    def classify_zero_shot(self, text):\n",
        "        return self._parse_output(self._generate(text))\n",
        "\n",
        "    def classify_one_shot(self, text):\n",
        "        return self._parse_output(self._generate(text, examples=[self.examples[0]]))\n",
        "\n",
        "    def classify_few_shot(self, text):\n",
        "        return self._parse_output(self._generate(text, examples=self.examples))\n",
        "\n",
        "    def probabilistic_classify(self, text, iterations=3):\n",
        "        results = {cls: 0 for cls in self.classes}\n",
        "        for _ in range(iterations):\n",
        "            temp = random.choice(self.temperatures)\n",
        "            pred = self.classify_zero_shot(text)  # Используем zero-shot для скорости\n",
        "            for cls in self.classes:\n",
        "                results[cls] += pred[cls]\n",
        "        total = sum(results.values())\n",
        "        return {k: v/total if total else 1/len(self.classes) for k, v in results.items()}\n",
        "\n",
        "    def evaluate(self, texts, true_labels):\n",
        "        results = {\n",
        "            \"Zero-shot\": [],\n",
        "            \"One-shot\": [],\n",
        "            \"Few-shot\": [],\n",
        "            \"Probabilistic\": []\n",
        "        }\n",
        "\n",
        "        for i, text in enumerate(texts):\n",
        "            print(f\"\\nОбработка текста {i+1}/{len(texts)}\")\n",
        "\n",
        "            # Zero-shot\n",
        "            zero_pred = self.classify_zero_shot(text)\n",
        "            results[\"Zero-shot\"].append(max(zero_pred, key=zero_pred.get))\n",
        "\n",
        "            # One-shot\n",
        "            one_pred = self.classify_one_shot(text)\n",
        "            results[\"One-shot\"].append(max(one_pred, key=one_pred.get))\n",
        "\n",
        "            # Few-shot\n",
        "            few_pred = self.classify_few_shot(text)\n",
        "            results[\"Few-shot\"].append(max(few_pred, key=few_pred.get))\n",
        "\n",
        "            # Probabilistic\n",
        "            prob_pred = self.probabilistic_classify(text)\n",
        "            results[\"Probabilistic\"].append(max(prob_pred, key=prob_pred.get))\n",
        "\n",
        "        # Расчет точности\n",
        "        scores = {}\n",
        "        for method, preds in results.items():\n",
        "            scores[method] = accuracy_score(true_labels, preds)\n",
        "\n",
        "        return scores\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    samples = [\n",
        "        (\"Футбольный матч между сборными России и Германии завершился со счётом 2:1 в пользу хозяев.\", \"sport\"),\n",
        "        (\"Блокчейн-платформа Ethereum перешла на энергоэффективный алгоритм PoS, снизив потребление энергии на 99.95%.\", \"technology\"),\n",
        "        (\"Постный борщ с фасолью и свеклой: вкусный и полезный вариант для вегетарианцев.\", \"culinary\"),\n",
        "        (\"Совет Безопасности ООН провёл экстренное заседание по ситуации на Ближнем Востоке.\", \"politics\"),\n",
        "        (\"Исследование Университета Гарварда: регулярные прогулки снижают риск сердечно-сосудистых заболеваний на 40%.\", \"health\")\n",
        "    ]\n",
        "\n",
        "    texts = [item[0] for item in samples]\n",
        "    labels = [item[1] for item in samples]\n",
        "\n",
        "    print(\"Инициализация модели...\")\n",
        "    classifier = TextClassifier()\n",
        "\n",
        "    print(\"Запуск оценки...\")\n",
        "    scores = classifier.evaluate(texts, labels)\n",
        "\n",
        "    print(\"\\nРезультаты:\")\n",
        "    for method, accuracy in scores.items():\n",
        "        print(f\"{method}: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "AfQhw6pSr1EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05a12a0e-d10a-4099-905f-86aa237dd10c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Инициализация модели...\n",
            "Запуск оценки...\n",
            "\n",
            "Обработка текста 1/5\n",
            "\n",
            "Обработка текста 2/5\n",
            "\n",
            "Обработка текста 3/5\n",
            "\n",
            "Обработка текста 4/5\n",
            "\n",
            "Обработка текста 5/5\n",
            "\n",
            "Результаты:\n",
            "Zero-shot: 0.20\n",
            "One-shot: 0.20\n",
            "Few-shot: 0.20\n",
            "Probabilistic: 0.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы:**\n",
        "\n",
        "* Разработана система классификации текстов на 5 категорий (sport, technology, culinary, politics, health)\n",
        "\n",
        "Реализованы 4 метода классификации:\n",
        "\n",
        "Zero-shot (классификация только по инструкции)\n",
        "\n",
        "One-shot (с одним примером)\n",
        "\n",
        "Few-shot (с несколькими примерами)\n",
        "\n",
        "Вероятностный подход (усреднение многократных предсказаний)\n",
        "\n",
        "Протестирована модель Qwen-0.6B на 5 текстах с известными метками\n",
        "\n",
        "Рассчитана точность каждого метода\n",
        "\n",
        "* Текущая реализация показала неудовлетворительные результаты (20% точности), что указывает на необходимость фундаментального пересмотра подхода. Одинаково низкие результаты всех методов классификации свидетельствуют о системной проблеме, вероятно связанной с:\n",
        "\n",
        "Неадекватностью промптов для данной модели\n",
        "\n",
        "Ошибками в обработке ответов\n",
        "\n",
        "Фундаментальным несоответствием между задачей и возможностями модели"
      ],
      "metadata": {
        "id": "DHVW8HEMyon1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7w2mE0TbzM2U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
